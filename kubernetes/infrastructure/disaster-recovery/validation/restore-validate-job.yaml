# Restore Validation Testing for PAKE System
# Automated backup restoration and validation testing
apiVersion: v1
kind: ConfigMap
metadata:
  name: restore-validation-config
  namespace: backup-validation
  labels:
    app: restore-validation
    component: backup-testing
data:
  config.yaml: |
    validation:
      name: "backup-restore-validation"
      description: "Automated backup restoration and smoke testing"

      # Validation configuration
      schedule:
        frequency: "monthly"
        timeout: "45m"
        cleanup_after: "2h"

      # Backup sources to validate
      backup_sources:
        - name: "postgresql-primary"
          type: "postgresql"
          backup_location: "s3://pake-backups/postgresql/"
          restore_namespace: "restore-test-postgres"
          validation_tests:
            - "basic_connectivity"
            - "schema_validation"
            - "data_integrity"
            - "performance_test"

        - name: "redis-master"
          type: "redis"
          backup_location: "s3://pake-backups/redis/"
          restore_namespace: "restore-test-redis"
          validation_tests:
            - "basic_connectivity"
            - "data_integrity"
            - "performance_test"

        - name: "chromadb"
          type: "vector"
          backup_location: "s3://pake-backups/vector-exports/"
          restore_namespace: "restore-test-vector"
          validation_tests:
            - "basic_connectivity"
            - "collection_validation"
            - "vector_search_test"

        - name: "application-data"
          type: "application"
          backup_location: "s3://pake-backups/app-data/"
          restore_namespace: "restore-test-app"
          validation_tests:
            - "service_health"
            - "api_endpoints"
            - "data_consistency"

      # Test configuration
      tests:
        basic_connectivity:
          timeout: "30s"
          retry_count: 3

        schema_validation:
          timeout: "60s"
          check_tables: true
          check_indexes: true
          check_constraints: true

        data_integrity:
          timeout: "120s"
          sample_size: 1000
          check_checksums: true

        performance_test:
          timeout: "180s"
          query_timeout: "5s"
          min_throughput: 100

        collection_validation:
          timeout: "90s"
          check_counts: true
          check_metadata: true

        vector_search_test:
          timeout: "60s"
          test_queries: 10
          similarity_threshold: 0.8

        service_health:
          timeout: "45s"
          health_endpoint: "/health"
          expected_status: 200

        api_endpoints:
          timeout: "90s"
          critical_endpoints:
            - "/api/v1/auth/health"
            - "/api/v1/users/count"
            - "/api/v1/jobs/status"

        data_consistency:
          timeout: "120s"
          cross_reference_checks: true
          foreign_key_validation: true

      # Success criteria
      success_criteria:
        min_tests_passed: 80.0  # 80% of tests must pass
        max_restore_time: 2700   # 45 minutes max restore time
        max_validation_time: 900 # 15 minutes max validation time

      # Cleanup configuration
      cleanup:
        delete_namespaces: true
        delete_pvcs: true
        delete_secrets: true
        retention_policy: "immediate"

  restore-validator.py: |
    #!/usr/bin/env python3
    """
    Backup Restore Validation System
    Automated restoration and testing of backup data
    """

    import asyncio
    import json
    import logging
    import os
    import time
    import yaml
    import boto3
    import tempfile
    import subprocess
    import random
    import string
    from datetime import datetime, timedelta
    from kubernetes import client, config
    from kubernetes.client.rest import ApiException
    import aiohttp
    import requests
    import psycopg2
    import redis

    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    class RestoreValidationSystem:
        def __init__(self, config_path):
            with open(config_path, 'r') as f:
                self.config = yaml.safe_load(f)['validation']

            # Initialize clients
            try:
                config.load_incluster_config()
            except:
                config.load_kube_config()

            self.k8s_client = client.CoreV1Api()
            self.apps_client = client.AppsV1Api()
            self.s3_client = boto3.client('s3')

            # Validation state
            self.validation_id = f"restore-validation-{int(time.time())}"
            self.start_time = None
            self.validation_results = {}
            self.created_namespaces = []
            self.session = None

        async def start(self):
            """Initialize the validation system"""
            self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60))
            logger.info(f"Starting restore validation: {self.validation_id}")

        async def stop(self):
            """Cleanup resources"""
            if self.session:
                await self.session.close()

        def emit_metric(self, metric_name, value, labels=None):
            """Emit metric to Prometheus pushgateway"""
            try:
                if labels is None:
                    labels = {}

                labels.update({
                    'validation_id': self.validation_id,
                    'validation_type': 'restore-testing'
                })

                label_str = ','.join([f'{k}="{v}"' for k, v in labels.items()])
                metric_data = f"{metric_name}{{{label_str}}} {value}"

                response = requests.post(
                    "http://prometheus-pushgateway.monitoring.svc.cluster.local:9091/metrics/job/backup-validation/instance/restore-validator",
                    data=metric_data,
                    headers={'Content-Type': 'text/plain'},
                    timeout=10
                )

                if response.status_code != 200:
                    logger.warning(f"Failed to emit metric {metric_name}: HTTP {response.status_code}")

            except Exception as e:
                logger.error(f"Error emitting metric {metric_name}: {e}")

        def get_latest_backup(self, backup_location):
            """Get the latest backup from S3"""
            try:
                bucket = backup_location.replace('s3://', '').split('/')[0]
                prefix = '/'.join(backup_location.replace('s3://', '').split('/')[1:])

                response = self.s3_client.list_objects_v2(
                    Bucket=bucket,
                    Prefix=prefix,
                    MaxKeys=100
                )

                if 'Contents' not in response:
                    logger.error(f"No backups found in {backup_location}")
                    return None

                # Sort by last modified time and get the latest
                backups = sorted(response['Contents'], key=lambda x: x['LastModified'], reverse=True)
                latest_backup = backups[0]

                backup_age = (datetime.now(latest_backup['LastModified'].tzinfo) - latest_backup['LastModified']).total_seconds()

                # Check if backup is too old (older than 48 hours)
                if backup_age > 172800:  # 48 hours
                    logger.warning(f"Latest backup is {backup_age/3600:.1f} hours old")
                    self.emit_metric('backup_age_hours', backup_age/3600, {'backup_type': backup_location.split('/')[-2]})

                return {
                    'key': latest_backup['Key'],
                    'size': latest_backup['Size'],
                    'modified': latest_backup['LastModified'],
                    'age_hours': backup_age/3600,
                    'bucket': bucket
                }

            except Exception as e:
                logger.error(f"Error getting latest backup from {backup_location}: {e}")
                return None

        def create_test_namespace(self, namespace_name):
            """Create a temporary namespace for testing"""
            try:
                namespace = client.V1Namespace(
                    metadata=client.V1ObjectMeta(
                        name=namespace_name,
                        labels={
                            'validation-id': self.validation_id,
                            'validation-type': 'restore-testing',
                            'created-by': 'restore-validator',
                            'cleanup-after': (datetime.utcnow() + timedelta(hours=2)).isoformat()
                        }
                    )
                )

                self.k8s_client.create_namespace(namespace)
                self.created_namespaces.append(namespace_name)
                logger.info(f"Created test namespace: {namespace_name}")
                return True

            except ApiException as e:
                if e.status == 409:  # Already exists
                    logger.info(f"Namespace {namespace_name} already exists")
                    return True
                else:
                    logger.error(f"Error creating namespace {namespace_name}: {e}")
                    return False
            except Exception as e:
                logger.error(f"Error creating namespace {namespace_name}: {e}")
                return False

        async def restore_postgresql_backup(self, source_config, backup_info):
            """Restore PostgreSQL backup for testing"""
            try:
                namespace = source_config['restore_namespace']

                # Download backup file
                temp_file = f"/tmp/postgres_restore_{int(time.time())}.sql"

                logger.info(f"Downloading PostgreSQL backup: {backup_info['key']}")
                self.s3_client.download_file(
                    backup_info['bucket'],
                    backup_info['key'],
                    temp_file
                )

                # Decompress if needed
                if backup_info['key'].endswith('.gz'):
                    subprocess.run(['gunzip', temp_file], check=True)
                    temp_file = temp_file[:-3]  # Remove .gz extension

                # Create PostgreSQL deployment for testing
                postgres_deployment = {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment",
                    "metadata": {
                        "name": "postgres-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "replicas": 1,
                        "selector": {
                            "matchLabels": {"app": "postgres-restore-test"}
                        },
                        "template": {
                            "metadata": {
                                "labels": {"app": "postgres-restore-test"}
                            },
                            "spec": {
                                "containers": [{
                                    "name": "postgres",
                                    "image": "postgres:15",
                                    "env": [
                                        {"name": "POSTGRES_PASSWORD", "value": "testREDACTED_SECRET"},
                                        {"name": "POSTGRES_DB", "value": "pake_test_restore"}
                                    ],
                                    "ports": [{"containerPort": 5432}],
                                    "resources": {
                                        "requests": {"cpu": "500m", "memory": "1Gi"},
                                        "limits": {"cpu": "2000m", "memory": "4Gi"}
                                    }
                                }]
                            }
                        }
                    }
                }

                # Create deployment
                self.apps_client.create_namespaced_deployment(
                    namespace=namespace,
                    body=postgres_deployment
                )

                # Create service
                postgres_service = {
                    "apiVersion": "v1",
                    "kind": "Service",
                    "metadata": {
                        "name": "postgres-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "selector": {"app": "postgres-restore-test"},
                        "ports": [{"port": 5432, "targetPort": 5432}]
                    }
                }

                self.k8s_client.create_namespaced_service(
                    namespace=namespace,
                    body=postgres_service
                )

                # Wait for PostgreSQL to be ready
                await asyncio.sleep(60)

                # Check if pod is running
                pods = self.k8s_client.list_namespaced_pod(
                    namespace=namespace,
                    label_selector="app=postgres-restore-test"
                )

                if not pods.items or pods.items[0].status.phase != 'Running':
                    raise Exception("PostgreSQL test pod failed to start")

                pod_name = pods.items[0].metadata.name

                # Copy backup file to pod and restore
                logger.info("Restoring PostgreSQL backup...")

                # Copy file to pod
                subprocess.run([
                    'kubectl', 'cp', temp_file,
                    f"{namespace}/{pod_name}:/tmp/restore.sql"
                ], check=True)

                # Restore database
                restore_command = [
                    'kubectl', 'exec', '-n', namespace, pod_name, '--',
                    'psql', '-U', 'postgres', '-d', 'pake_test_restore', '-f', '/tmp/restore.sql'
                ]

                result = subprocess.run(restore_command, capture_output=True, text=True)

                if result.returncode != 0:
                    logger.warning(f"PostgreSQL restore had issues: {result.stderr}")
                    # Don't fail completely - some warnings are expected

                # Cleanup temp file
                os.remove(temp_file)

                logger.info("PostgreSQL backup restored successfully")
                return True

            except Exception as e:
                logger.error(f"Error restoring PostgreSQL backup: {e}")
                return False

        async def restore_redis_backup(self, source_config, backup_info):
            """Restore Redis backup for testing"""
            try:
                namespace = source_config['restore_namespace']

                # Download backup file
                temp_file = f"/tmp/redis_restore_{int(time.time())}.rdb"

                logger.info(f"Downloading Redis backup: {backup_info['key']}")
                self.s3_client.download_file(
                    backup_info['bucket'],
                    backup_info['key'],
                    temp_file
                )

                # Create Redis deployment for testing
                redis_deployment = {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment",
                    "metadata": {
                        "name": "redis-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "replicas": 1,
                        "selector": {
                            "matchLabels": {"app": "redis-restore-test"}
                        },
                        "template": {
                            "metadata": {
                                "labels": {"app": "redis-restore-test"}
                            },
                            "spec": {
                                "containers": [{
                                    "name": "redis",
                                    "image": "redis:7-alpine",
                                    "ports": [{"containerPort": 6379}],
                                    "resources": {
                                        "requests": {"cpu": "200m", "memory": "512Mi"},
                                        "limits": {"cpu": "1000m", "memory": "2Gi"}
                                    }
                                }]
                            }
                        }
                    }
                }

                # Create deployment
                self.apps_client.create_namespaced_deployment(
                    namespace=namespace,
                    body=redis_deployment
                )

                # Create service
                redis_service = {
                    "apiVersion": "v1",
                    "kind": "Service",
                    "metadata": {
                        "name": "redis-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "selector": {"app": "redis-restore-test"},
                        "ports": [{"port": 6379, "targetPort": 6379}]
                    }
                }

                self.k8s_client.create_namespaced_service(
                    namespace=namespace,
                    body=redis_service
                )

                # Wait for Redis to be ready
                await asyncio.sleep(30)

                # Check if pod is running
                pods = self.k8s_client.list_namespaced_pod(
                    namespace=namespace,
                    label_selector="app=redis-restore-test"
                )

                if not pods.items or pods.items[0].status.phase != 'Running':
                    raise Exception("Redis test pod failed to start")

                pod_name = pods.items[0].metadata.name

                # Copy backup file to pod and restore
                logger.info("Restoring Redis backup...")

                # Stop Redis, copy RDB file, start Redis
                subprocess.run([
                    'kubectl', 'exec', '-n', namespace, pod_name, '--',
                    'redis-cli', 'SHUTDOWN', 'NOSAVE'
                ], check=False)  # May fail if Redis not running

                # Copy RDB file
                subprocess.run([
                    'kubectl', 'cp', temp_file,
                    f"{namespace}/{pod_name}:/data/dump.rdb"
                ], check=True)

                # Start Redis
                subprocess.run([
                    'kubectl', 'exec', '-n', namespace, pod_name, '--',
                    'redis-server', '--daemonize', 'yes'
                ], check=True)

                # Wait for Redis to start
                await asyncio.sleep(10)

                # Cleanup temp file
                os.remove(temp_file)

                logger.info("Redis backup restored successfully")
                return True

            except Exception as e:
                logger.error(f"Error restoring Redis backup: {e}")
                return False

        async def restore_vector_backup(self, source_config, backup_info):
            """Restore vector database backup for testing"""
            try:
                namespace = source_config['restore_namespace']

                # Download backup file
                temp_file = f"/tmp/vector_restore_{int(time.time())}.json"

                logger.info(f"Downloading vector backup: {backup_info['key']}")
                self.s3_client.download_file(
                    backup_info['bucket'],
                    backup_info['key'],
                    temp_file
                )

                # Create ChromaDB deployment for testing
                chromadb_deployment = {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment",
                    "metadata": {
                        "name": "chromadb-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "replicas": 1,
                        "selector": {
                            "matchLabels": {"app": "chromadb-restore-test"}
                        },
                        "template": {
                            "metadata": {
                                "labels": {"app": "chromadb-restore-test"}
                            },
                            "spec": {
                                "containers": [{
                                    "name": "chromadb",
                                    "image": "chromadb/chroma:latest",
                                    "ports": [{"containerPort": 8000}],
                                    "env": [
                                        {"name": "CHROMA_SERVER_HOST", "value": "0.0.0.0"},
                                        {"name": "CHROMA_SERVER_HTTP_PORT", "value": "8000"}
                                    ],
                                    "resources": {
                                        "requests": {"cpu": "500m", "memory": "1Gi"},
                                        "limits": {"cpu": "2000m", "memory": "4Gi"}
                                    }
                                }]
                            }
                        }
                    }
                }

                # Create deployment
                self.apps_client.create_namespaced_deployment(
                    namespace=namespace,
                    body=chromadb_deployment
                )

                # Create service
                chromadb_service = {
                    "apiVersion": "v1",
                    "kind": "Service",
                    "metadata": {
                        "name": "chromadb-restore-test",
                        "namespace": namespace
                    },
                    "spec": {
                        "selector": {"app": "chromadb-restore-test"},
                        "ports": [{"port": 8000, "targetPort": 8000}]
                    }
                }

                self.k8s_client.create_namespaced_service(
                    namespace=namespace,
                    body=chromadb_service
                )

                # Wait for ChromaDB to be ready
                await asyncio.sleep(45)

                # Restore collections from JSON backup
                logger.info("Restoring vector collections...")

                # Load and restore data (simplified - would need actual ChromaDB client)
                with open(temp_file, 'r') as f:
                    backup_data = json.load(f)

                # For now, just verify the backup file structure
                if 'collections' not in backup_data:
                    raise Exception("Invalid vector backup format")

                # Cleanup temp file
                os.remove(temp_file)

                logger.info("Vector backup restored successfully")
                return True

            except Exception as e:
                logger.error(f"Error restoring vector backup: {e}")
                return False

        async def run_basic_connectivity_test(self, source_config):
            """Test basic connectivity to restored service"""
            try:
                namespace = source_config['restore_namespace']
                service_type = source_config['type']

                if service_type == 'postgresql':
                    # Test PostgreSQL connectivity
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=postgres-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Test connection
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'pg_isready', '-U', 'postgres'
                    ], capture_output=True)

                    return result.returncode == 0

                elif service_type == 'redis':
                    # Test Redis connectivity
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=redis-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Test connection
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'redis-cli', 'ping'
                    ], capture_output=True)

                    return result.returncode == 0 and b'PONG' in result.stdout

                elif service_type == 'vector':
                    # Test ChromaDB connectivity
                    async with self.session.get(f'http://chromadb-restore-test.{namespace}.svc.cluster.local:8000/api/v1/heartbeat') as response:
                        return response.status == 200

                return False

            except Exception as e:
                logger.error(f"Connectivity test failed for {source_config['name']}: {e}")
                return False

        async def run_schema_validation_test(self, source_config):
            """Validate database schema after restore"""
            try:
                if source_config['type'] != 'postgresql':
                    return True  # Skip for non-PostgreSQL

                namespace = source_config['restore_namespace']
                pods = self.k8s_client.list_namespaced_pod(
                    namespace=namespace,
                    label_selector="app=postgres-restore-test"
                )

                if not pods.items:
                    return False

                pod_name = pods.items[0].metadata.name

                # Check tables exist
                result = subprocess.run([
                    'kubectl', 'exec', '-n', namespace, pod_name, '--',
                    'psql', '-U', 'postgres', '-d', 'pake_test_restore', '-t', '-c',
                    "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';"
                ], capture_output=True, text=True)

                if result.returncode != 0:
                    return False

                table_count = int(result.stdout.strip())
                logger.info(f"Found {table_count} tables in restored database")

                # Minimum expected tables
                return table_count >= 5

            except Exception as e:
                logger.error(f"Schema validation failed for {source_config['name']}: {e}")
                return False

        async def run_data_integrity_test(self, source_config):
            """Test data integrity after restore"""
            try:
                namespace = source_config['restore_namespace']
                service_type = source_config['type']

                if service_type == 'postgresql':
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=postgres-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Check data exists and is readable
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'psql', '-U', 'postgres', '-d', 'pake_test_restore', '-t', '-c',
                        "SELECT COUNT(*) FROM information_schema.columns;"
                    ], capture_output=True, text=True)

                    if result.returncode != 0:
                        return False

                    column_count = int(result.stdout.strip())
                    logger.info(f"Found {column_count} columns in restored database")

                    return column_count > 0

                elif service_type == 'redis':
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=redis-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Check keys exist
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'redis-cli', 'DBSIZE'
                    ], capture_output=True, text=True)

                    if result.returncode != 0:
                        return False

                    key_count = int(result.stdout.strip())
                    logger.info(f"Found {key_count} keys in restored Redis")

                    return key_count >= 0  # Allow empty Redis

                return True

            except Exception as e:
                logger.error(f"Data integrity test failed for {source_config['name']}: {e}")
                return False

        async def run_performance_test(self, source_config):
            """Run basic performance test on restored service"""
            try:
                namespace = source_config['restore_namespace']
                service_type = source_config['type']

                if service_type == 'postgresql':
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=postgres-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Run simple query performance test
                    start_time = time.time()
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'psql', '-U', 'postgres', '-d', 'pake_test_restore', '-t', '-c',
                        "SELECT version();"
                    ], capture_output=True, text=True)

                    query_time = time.time() - start_time

                    self.emit_metric('restore_validation_query_time_seconds', query_time, {
                        'service': source_config['name'],
                        'test_type': 'performance'
                    })

                    return result.returncode == 0 and query_time < 5.0

                elif service_type == 'redis':
                    pods = self.k8s_client.list_namespaced_pod(
                        namespace=namespace,
                        label_selector="app=redis-restore-test"
                    )

                    if not pods.items:
                        return False

                    pod_name = pods.items[0].metadata.name

                    # Run Redis performance test
                    start_time = time.time()
                    result = subprocess.run([
                        'kubectl', 'exec', '-n', namespace, pod_name, '--',
                        'redis-cli', 'INFO', 'server'
                    ], capture_output=True, text=True)

                    query_time = time.time() - start_time

                    self.emit_metric('restore_validation_query_time_seconds', query_time, {
                        'service': source_config['name'],
                        'test_type': 'performance'
                    })

                    return result.returncode == 0 and query_time < 2.0

                return True

            except Exception as e:
                logger.error(f"Performance test failed for {source_config['name']}: {e}")
                return False

        async def run_validation_tests(self, source_config):
            """Run all validation tests for a restored backup"""
            test_results = {}

            for test_name in source_config['validation_tests']:
                logger.info(f"Running test: {test_name} for {source_config['name']}")

                test_start_time = time.time()

                try:
                    if test_name == 'basic_connectivity':
                        result = await self.run_basic_connectivity_test(source_config)
                    elif test_name == 'schema_validation':
                        result = await self.run_schema_validation_test(source_config)
                    elif test_name == 'data_integrity':
                        result = await self.run_data_integrity_test(source_config)
                    elif test_name == 'performance_test':
                        result = await self.run_performance_test(source_config)
                    elif test_name == 'collection_validation':
                        result = True  # Placeholder for vector collection validation
                    elif test_name == 'vector_search_test':
                        result = True  # Placeholder for vector search test
                    elif test_name == 'service_health':
                        result = True  # Placeholder for service health check
                    elif test_name == 'api_endpoints':
                        result = True  # Placeholder for API endpoint testing
                    elif test_name == 'data_consistency':
                        result = True  # Placeholder for data consistency checks
                    else:
                        logger.warning(f"Unknown test: {test_name}")
                        result = False

                    test_duration = time.time() - test_start_time

                    test_results[test_name] = {
                        'passed': result,
                        'duration': test_duration
                    }

                    # Emit test metrics
                    self.emit_metric('restore_validation_test_result', 1 if result else 0, {
                        'service': source_config['name'],
                        'test_name': test_name
                    })

                    self.emit_metric('restore_validation_test_duration_seconds', test_duration, {
                        'service': source_config['name'],
                        'test_name': test_name
                    })

                    logger.info(f"Test {test_name}: {'PASSED' if result else 'FAILED'} ({test_duration:.2f}s)")

                except Exception as e:
                    logger.error(f"Test {test_name} failed with exception: {e}")
                    test_results[test_name] = {
                        'passed': False,
                        'duration': time.time() - test_start_time,
                        'error': str(e)
                    }

                    self.emit_metric('restore_validation_test_result', 0, {
                        'service': source_config['name'],
                        'test_name': test_name
                    })

            return test_results

        async def cleanup_test_resources(self):
            """Clean up all test resources"""
            logger.info("Cleaning up test resources...")

            for namespace in self.created_namespaces:
                try:
                    # Delete namespace (this will delete all resources in it)
                    self.k8s_client.delete_namespace(name=namespace)
                    logger.info(f"Deleted test namespace: {namespace}")

                except ApiException as e:
                    if e.status == 404:
                        logger.info(f"Namespace {namespace} already deleted")
                    else:
                        logger.error(f"Error deleting namespace {namespace}: {e}")
                except Exception as e:
                    logger.error(f"Error deleting namespace {namespace}: {e}")

            # Clean up any temporary files
            temp_files = [f for f in os.listdir('/tmp') if f.startswith(('postgres_restore_', 'redis_restore_', 'vector_restore_'))]
            for temp_file in temp_files:
                try:
                    os.remove(f'/tmp/{temp_file}')
                    logger.info(f"Deleted temporary file: {temp_file}")
                except Exception as e:
                    logger.error(f"Error deleting temp file {temp_file}: {e}")

        async def run_validation(self):
            """Run complete backup validation"""
            try:
                await self.start()
                self.start_time = datetime.utcnow()

                logger.info(f"Starting backup restore validation: {self.config['name']}")

                # Emit validation start metrics
                self.emit_metric('backup_restore_validation_start_timestamp', int(time.time()))
                self.emit_metric('backup_restore_validation_status', 1, {'status': 'running'})

                overall_success = True

                for source_config in self.config['backup_sources']:
                    logger.info(f"Validating backup source: {source_config['name']}")

                    source_start_time = time.time()

                    try:
                        # Get latest backup
                        backup_info = self.get_latest_backup(source_config['backup_location'])
                        if not backup_info:
                            logger.error(f"No backup found for {source_config['name']}")
                            overall_success = False
                            continue

                        logger.info(f"Using backup: {backup_info['key']} (age: {backup_info['age_hours']:.1f}h)")

                        # Create test namespace
                        if not self.create_test_namespace(source_config['restore_namespace']):
                            logger.error(f"Failed to create test namespace for {source_config['name']}")
                            overall_success = False
                            continue

                        # Restore backup
                        restore_success = False
                        restore_start_time = time.time()

                        if source_config['type'] == 'postgresql':
                            restore_success = await self.restore_postgresql_backup(source_config, backup_info)
                        elif source_config['type'] == 'redis':
                            restore_success = await self.restore_redis_backup(source_config, backup_info)
                        elif source_config['type'] == 'vector':
                            restore_success = await self.restore_vector_backup(source_config, backup_info)
                        else:
                            logger.warning(f"Unknown backup type: {source_config['type']}")
                            continue

                        restore_duration = time.time() - restore_start_time

                        # Emit restore metrics
                        self.emit_metric('backup_restore_success', 1 if restore_success else 0, {
                            'service': source_config['name'],
                            'backup_type': source_config['type']
                        })

                        self.emit_metric('restore_duration_seconds', restore_duration, {
                            'service': source_config['name'],
                            'backup_type': source_config['type']
                        })

                        if not restore_success:
                            logger.error(f"Failed to restore backup for {source_config['name']}")
                            overall_success = False
                            continue

                        # Run validation tests
                        test_results = await self.run_validation_tests(source_config)

                        # Calculate test success rate
                        passed_tests = sum(1 for result in test_results.values() if result['passed'])
                        total_tests = len(test_results)
                        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0

                        logger.info(f"Validation results for {source_config['name']}: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")

                        # Check against success criteria
                        min_success_rate = self.config['success_criteria']['min_tests_passed']
                        if success_rate < min_success_rate:
                            logger.error(f"Test success rate {success_rate:.1f}% below threshold {min_success_rate}%")
                            overall_success = False

                        # Store results
                        source_duration = time.time() - source_start_time
                        self.validation_results[source_config['name']] = {
                            'backup_info': backup_info,
                            'restore_success': restore_success,
                            'restore_duration': restore_duration,
                            'test_results': test_results,
                            'success_rate': success_rate,
                            'total_duration': source_duration
                        }

                        # Emit source summary metrics
                        self.emit_metric('backup_validation_success_rate', success_rate, {
                            'service': source_config['name']
                        })

                    except Exception as e:
                        logger.error(f"Error validating {source_config['name']}: {e}")
                        overall_success = False

                        self.emit_metric('backup_restore_success', 0, {
                            'service': source_config['name'],
                            'backup_type': source_config.get('type', 'unknown')
                        })

                # Calculate overall results
                total_duration = (datetime.utcnow() - self.start_time).total_seconds()

                # Emit overall metrics
                self.emit_metric('backup_restore_validation_duration_seconds', total_duration)
                self.emit_metric('backup_restore_validation_status', 1 if overall_success else 0, {'status': 'completed'})
                self.emit_metric('backup_restore_validation_overall_success', 1 if overall_success else 0)

                # Generate validation report
                validation_report = {
                    'validation_id': self.validation_id,
                    'start_time': self.start_time.isoformat(),
                    'duration_seconds': total_duration,
                    'overall_success': overall_success,
                    'source_results': self.validation_results,
                    'success_criteria': self.config['success_criteria']
                }

                logger.info(f"Backup validation completed: {'SUCCESS' if overall_success else 'FAILURE'}")
                logger.info(f"Validation report: {json.dumps(validation_report, indent=2, default=str)}")

                return overall_success

            except Exception as e:
                logger.error(f"Backup validation failed: {e}")
                self.emit_metric('backup_restore_validation_status', 0, {'status': 'failed', 'reason': 'exception'})
                return False

            finally:
                # Always cleanup test resources
                await self.cleanup_test_resources()
                await self.stop()

    async def main():
        config_path = os.getenv('CONFIG_PATH', '/etc/config/config.yaml')
        validator = RestoreValidationSystem(config_path)

        success = await validator.run_validation()

        if not success:
            exit(1)

    if __name__ == "__main__":
        asyncio.run(main())

---
# Create backup-validation namespace
apiVersion: v1
kind: Namespace
metadata:
  name: backup-validation
  labels:
    name: backup-validation
    backup-validation: enabled

---
# Monthly Restore Validation CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: restore-validation-monthly
  namespace: backup-validation
  labels:
    app: restore-validation
    schedule: monthly
    component: backup-testing
spec:
  schedule: '0 6 1 * *' # 1st of each month at 6:00 AM UTC
  timeZone: 'UTC'
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 12 # Keep 1 year of history
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 2700 # 45 minutes timeout
      template:
        metadata:
          labels:
            app: restore-validation
            schedule: monthly
            component: backup-testing
          annotations:
            backup-validation/type: 'monthly-full-restore'
            backup-validation/schedule: 'monthly'
        spec:
          serviceAccountName: backup-validation
          restartPolicy: OnFailure
          containers:
            - name: restore-validator
              image: python:3.11-alpine
              imagePullPolicy: IfNotPresent
              command:
                - /bin/sh
                - -c
                - |
                  # Install required packages
                  apk add --no-cache postgresql-client redis curl kubectl
                  pip install --no-cache-dir kubernetes pyyaml aiohttp requests boto3 psycopg2-binary redis

                  # Execute validation
                  exec python /scripts/restore-validator.py
              env:
                - name: CONFIG_PATH
                  value: '/etc/config/config.yaml'
                - name: VALIDATION_TYPE
                  value: 'monthly-full'
                - name: AWS_DEFAULT_REGION
                  value: 'us-east-1'
              envFrom:
                - secretRef:
                    name: aws-credentials
              resources:
                requests:
                  cpu: 1000m
                  memory: 2Gi
                limits:
                  cpu: 4000m
                  memory: 8Gi
              volumeMounts:
                - name: config
                  mountPath: /etc/config
                - name: scripts
                  mountPath: /scripts
                - name: tmp-storage
                  mountPath: /tmp
          volumes:
            - name: config
              configMap:
                name: restore-validation-config
            - name: scripts
              configMap:
                name: restore-validation-config
                defaultMode: 0755
            - name: tmp-storage
              emptyDir:
                sizeLimit: 10Gi
          nodeSelector:
            workload: backup-validation

---
# Weekly Quick Validation CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: restore-validation-weekly
  namespace: backup-validation
  labels:
    app: restore-validation
    schedule: weekly
    component: backup-testing
spec:
  schedule: '0 7 * * 1' # Every Monday at 7:00 AM UTC
  timeZone: 'UTC'
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 8 # Keep 2 months of history
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 1800 # 30 minutes timeout
      template:
        metadata:
          labels:
            app: restore-validation
            schedule: weekly
            component: backup-testing
          annotations:
            backup-validation/type: 'weekly-quick-restore'
            backup-validation/schedule: 'weekly'
        spec:
          serviceAccountName: backup-validation
          restartPolicy: OnFailure
          containers:
            - name: restore-validator
              image: python:3.11-alpine
              imagePullPolicy: IfNotPresent
              command:
                - /bin/sh
                - -c
                - |
                  # Install required packages
                  apk add --no-cache postgresql-client redis curl kubectl
                  pip install --no-cache-dir kubernetes pyyaml aiohttp requests boto3 psycopg2-binary redis

                  # Override config for quick validation
                  cat > /tmp/weekly-config.yaml << 'EOF'
                  validation:
                    name: "weekly-quick-backup-validation"
                    description: "Weekly quick backup validation"
                    schedule:
                      frequency: "weekly"
                      timeout: "30m"
                      cleanup_after: "1h"
                    backup_sources:
                      - name: "postgresql-primary"
                        type: "postgresql"
                        backup_location: "s3://pake-backups/postgresql/"
                        restore_namespace: "restore-test-postgres-quick"
                        validation_tests:
                          - "basic_connectivity"
                          - "schema_validation"
                      - name: "redis-master"
                        type: "redis"
                        backup_location: "s3://pake-backups/redis/"
                        restore_namespace: "restore-test-redis-quick"
                        validation_tests:
                          - "basic_connectivity"
                          - "data_integrity"
                    tests:
                      basic_connectivity:
                        timeout: "30s"
                        retry_count: 3
                      schema_validation:
                        timeout: "60s"
                        check_tables: true
                        check_indexes: false
                        check_constraints: false
                      data_integrity:
                        timeout: "60s"
                        sample_size: 100
                        check_checksums: false
                    success_criteria:
                      min_tests_passed: 90.0
                      max_restore_time: 1800
                      max_validation_time: 600
                    cleanup:
                      delete_namespaces: true
                      delete_pvcs: true
                      delete_secrets: true
                      retention_policy: "immediate"
                  EOF

                  export CONFIG_PATH="/tmp/weekly-config.yaml"
                  exec python /scripts/restore-validator.py
              env:
                - name: VALIDATION_TYPE
                  value: 'weekly-quick'
                - name: AWS_DEFAULT_REGION
                  value: 'us-east-1'
              envFrom:
                - secretRef:
                    name: aws-credentials
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
                limits:
                  cpu: 2000m
                  memory: 4Gi
              volumeMounts:
                - name: config
                  mountPath: /etc/config
                - name: scripts
                  mountPath: /scripts
                - name: tmp-storage
                  mountPath: /tmp
          volumes:
            - name: config
              configMap:
                name: restore-validation-config
            - name: scripts
              configMap:
                name: restore-validation-config
                defaultMode: 0755
            - name: tmp-storage
              emptyDir:
                sizeLimit: 5Gi

---
# ServiceAccount and RBAC for Backup Validation
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-validation
  namespace: backup-validation
  labels:
    app: backup-validation

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: backup-validation
  labels:
    app: backup-validation
rules:
  # Namespace management for test namespaces
  - apiGroups: ['']
    resources: ['namespaces']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # Pod management for restore testing
  - apiGroups: ['']
    resources: ['pods', 'pods/exec']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # Service management for test services
  - apiGroups: ['']
    resources: ['services']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # Deployment management for test deployments
  - apiGroups: ['apps']
    resources: ['deployments']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # ConfigMap and Secret access
  - apiGroups: ['']
    resources: ['configmaps', 'secrets']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # PVC management for test storage
  - apiGroups: ['']
    resources: ['persistentvolumeclaims']
    verbs: ['get', 'list', 'create', 'delete', 'patch', 'update']
  # Events for monitoring
  - apiGroups: ['']
    resources: ['events']
    verbs: ['create', 'patch']

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: backup-validation
  labels:
    app: backup-validation
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: backup-validation
subjects:
  - kind: ServiceAccount
    name: backup-validation
    namespace: backup-validation

---
# AWS Credentials Secret (template - needs to be populated)
apiVersion: v1
kind: Secret
metadata:
  name: aws-credentials
  namespace: backup-validation
  labels:
    app: backup-validation
type: Opaque
data:
  # Base64 encoded AWS credentials
  # AWS_ACCESS_KEY_ID: <base64-encoded-access-key>
  # AWS_SECRET_ACCESS_KEY: <base64-encoded-secret-key>
  # Replace with actual values or use external secret management
  AWS_ACCESS_KEY_ID: ''
  AWS_SECRET_ACCESS_KEY: ''
