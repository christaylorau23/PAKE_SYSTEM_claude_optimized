# Logstash Configuration for AI Security Monitoring

input {
  # File input for application logs
  file {
    path => "/logs/**/*.log"
    start_position => "beginning"
    sincedb_path => "/tmp/sincedb"
    codec => "json"
    tags => ["application_log"]
  }
  
  # Beats input for structured logs
  beats {
    port => 5044
    tags => ["beats"]
  }
  
  # HTTP input for direct log shipping
  http {
    port => 8080
    codec => "json"
    tags => ["http_input"]
  }
  
  # Syslog input for system logs
  syslog {
    port => 514
    tags => ["syslog"]
  }
}

filter {
  # Parse timestamps
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "dd/MMM/yyyy:HH:mm:ss Z" ]
    target => "@timestamp"
  }
  
  # Extract IP addresses
  if [source_ip] {
    mutate {
      add_field => { "client_ip" => "%{source_ip}" }
    }
  }
  
  # Parse user agents
  if [user_agent] {
    useragent {
      source => "user_agent"
      target => "ua"
    }
  }
  
  # Security-specific parsing
  if "security" in [tags] {
    mutate {
      add_field => { "log_type" => "security" }
    }
  }
  
  # Failed login detection
  if [message] =~ /(?i)(failed|invalid|unauthorized|denied).*(?i)(login|auth|credential)/ {
    mutate {
      add_field => { "security_event" => "failed_login" }
      add_field => { "severity" => "medium" }
    }
  }
  
  # SQL injection detection
  if [message] =~ /(?i)(union|select|insert|update|delete).*(--|\/\*)/ or [message] =~ /(?i)(or.*1=1|drop.*table)/ {
    mutate {
      add_field => { "security_event" => "sql_injection" }
      add_field => { "severity" => "critical" }
    }
  }
  
  # XSS detection
  if [message] =~ /<script.*?>|javascript:|onerror.*=|alert\(/ {
    mutate {
      add_field => { "security_event" => "xss_attempt" }
      add_field => { "severity" => "high" }
    }
  }
  
  # Path traversal detection
  if [message] =~ /\.\.\/(\.\.\/)+|\.\.\\(\.\.\\)+|\/etc\/passwd|\/windows\/system32/ {
    mutate {
      add_field => { "security_event" => "path_traversal" }
      add_field => { "severity" => "critical" }
    }
  }
  
  # Slow query detection
  if [message] =~ /(?i)slow.*query|execution.*time.*\d{3,}|timeout.*exceeded/ {
    # Extract execution time if present
    grok {
      match => { "message" => "(?<execution_time>\d+\.?\d*)\s*(?:ms|seconds?|s)" }
      tag_on_failure => ["_grokparsefailure_execution_time"]
    }
    
    if [execution_time] {
      mutate {
        convert => { "execution_time" => "float" }
        add_field => { "security_event" => "slow_query" }
        add_field => { "severity" => "low" }
      }
    }
  }
  
  # Rate limiting detection (based on request frequency)
  # This would require additional plugins or external processing
  
  # GeoIP enrichment for external IPs
  if [client_ip] and [client_ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
  
  # Add processing metadata
  mutate {
    add_field => { "processed_at" => "%{@timestamp}" }
    add_field => { "logstash_host" => "%{[@metadata][host]}" }
  }
  
  # Remove sensitive data (optional)
  if [REDACTED_SECRET] {
    mutate {
      remove_field => [ "REDACTED_SECRET" ]
    }
  }
  
  # Clean up empty fields
  mutate {
    remove_field => [ "@version" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # Index strategy based on log type and date
    index => "logs-%{+YYYY.MM.dd}"
    
    # Security events get special index
    if [security_event] {
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "security-events-%{+YYYY.MM.dd}"
      }
    }
    
    # Template for index mapping
    template_name => "security_logs"
    template_pattern => ["logs-*", "security-*"]
    template => "/usr/share/logstash/templates/security-template.json"
    template_overwrite => true
  }
  
  # Debug output (optional)
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }
}